{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:75%; text-align:right;\">\n",
    "    <img src=\"img/data_ev_unsplash.jpg\" width=\"width\" height=\"height\" style=\"padding-bottom:0.2em;\" />\n",
    "    <figcaption>Photo by ev on Unsplash</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to machine learning in Python with scikit-learn\n",
    "\n",
    "**Applied Programming - Summer term 2020 - FOM Hochschule für Oekonomie und Management - Cologne**\n",
    "\n",
    "**Lecture 06 - May 07, 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Recap and outlook](#recap)\n",
    "* [Business understanding](#businessunderstanding)\n",
    "* [Data understanding](#dataunderstanding)\n",
    "* [Data preparation](#preparation)\n",
    "* [Modeling and evaluation](#modeling)\n",
    "* [Homework](#homework)\n",
    "* [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap and outlook<a class=\"anchor\" id=\"recap\"></a>\n",
    "In the last lecture we learned about important packages to extend the functionality of Python. Concerning machine learning, we looked at the scikit-learn package.\n",
    "\n",
    "> *Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.* [[1]](#sklearn2020)\n",
    "\n",
    "Important features of the scikit-learn library are:\n",
    "* Supervised and unsupervised learning algorithms\n",
    "* Clean, uniform, and streamlined API\n",
    "* In-depth, well understandable documentation with references to scientific papers\n",
    "\n",
    "In this lecture we will mainly focus on the implementation of the different machine learning algorithms - so we will primarily discuss the section modeling in CRISP-DM. In the homework following this lecture you will deepen the preprocessing by means of an example data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business understanding<a class=\"anchor\" id=\"businessunderstanding\"></a>\n",
    "A major issue for businesses that assign appointments to their customers is not showing up. This is especially important for medical offices, as treatment times are reserved and then expire unused, although others would have needed them. The reduction of such cases is therefore in the interest of all parties involved. Medical practices do not suffer losses due to unused capacity and other patients are given treatment. Support in the form of a predictive algorithm would therefore be highly desirable.\n",
    "\n",
    "What possible measures could be taken if the prediction is successful? If a patient is found to have an increased risk of no-shows, it is possible to deliberately over-plan - i.e. to double the number of treatment appointments. Or measures can be introduced to make the patient aware of the appointment. Various applications for a predictive no-show score are therefore conceivable.\n",
    "\n",
    "The data set used here includes appointments and information on the patient from the Brazilian city of Vitória [[2]](#jonihoppen2017). Vitória has about 360.000 inhabitants and is located 530km north-east of Rio de Janeiro on the Atlantic coast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding<a class=\"anchor\" id=\"dataunderstanding\"></a>\n",
    "First we load the data into the notebook and examine the scope, type and properties of the data.\n",
    "\n",
    "The documentation attached to the data includes the following descriptions of the columns:\n",
    "* ``PatientId``: Identification of a patient\n",
    "* ``AppointmentID``: Identification of each appointment\n",
    "* ``Gender``: Male or Female . Female is the greater proportion, woman takes way more care of they health in comparison to man\n",
    "* ``ScheduledDay``: The day someone called or registered the appointment, this is before appointment of course\n",
    "* ``AppointmentDay``: The day of the actuall appointment, when they have to visit the doctor\n",
    "* ``Age``: How old is the patient\n",
    "* ``Neighbourhood``: Where the appointment takes place\n",
    "* ``Scholarship``: True of false; state social support programme\n",
    "* ``Hipertension``: True or false\n",
    "* ``Diabetes``: True or false\n",
    "* ``Alcoholism``: True or false\n",
    "* ``Handcap``: True or false\n",
    "* ``SMS_received``: 1 or more messages sent to the patient\n",
    "* ``No-show``: True or false.\n",
    "\n",
    "For the examination of the data, keep the following questions in mind:\n",
    "* *What stands out to you?*\n",
    "* *Which pre-processing steps will be necessary?*\n",
    "* *What is the name of the label variable for which supervised learning can take place?*\n",
    "* *Is it a classification or regression problem?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and a first look at a random sample\n",
    "df = pd.read_csv('dat/noshow.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Basic statistics of all columns\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'], format = '%Y-%m-%dT%H:%M:%SZ')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print('Values of Gender:       {}'.format(df['Gender'].unique()))\n",
    "print('Values of Scholarship:  {}'.format(df['Scholarship'].unique()))\n",
    "print('Values of Hipertension: {}'.format(df['Hipertension'].unique()))\n",
    "print('Values of Diabetes:     {}'.format(df['Diabetes'].unique()))\n",
    "print('Values of Alcoholism:   {}'.format(df['Alcoholism'].unique()))\n",
    "print('Values of Handcap:      {}'.format(df['Handcap'].unique()))\n",
    "print('Values of SMS_received: {}'.format(df['SMS_received'].unique()))\n",
    "print('Values of No-show:      {}'.format(df['No-show'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print('Values of Age: {}'.format(np.sort(df['Age'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(len(df.columns[df.isna().any()])/len(df.columns))\n",
    "print(df.isnull().sum().sum()/np.product(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "fig, ax = plt.subplots(nrows = 4, ncols = 3, figsize = (20, 15))\n",
    "ax[0, 0].hist(df['Gender'])\n",
    "ax[0, 0].set_title('Gender')\n",
    "ax[0, 1].hist(df['ScheduledDay'])\n",
    "ax[0, 1].set_title('ScheduledDay')\n",
    "ax[0, 2].hist(df['AppointmentDay'])\n",
    "ax[0, 2].set_title('AppointmentDay')\n",
    "ax[1, 0].hist(df['Age'])\n",
    "ax[1, 0].set_title('Age')\n",
    "ax[1, 1].hist(df['Neighbourhood'])\n",
    "ax[1, 1].set_title('Neighbourhood')\n",
    "ax[1, 2].hist(df['Scholarship'])\n",
    "ax[1, 2].set_title('Scholarship')\n",
    "ax[2, 0].hist(df['Hipertension'])\n",
    "ax[2, 0].set_title('Hipertension')\n",
    "ax[2, 1].hist(df['Diabetes'])\n",
    "ax[2, 1].set_title('Diabetes')\n",
    "ax[2, 2].hist(df['Alcoholism'])\n",
    "ax[2, 2].set_title('Alcoholism')\n",
    "ax[3, 0].hist(df['Handcap'])\n",
    "ax[3, 0].set_title('Handcap')\n",
    "ax[3, 1].hist(df['SMS_received'])\n",
    "ax[3, 1].set_title('SMS_received')\n",
    "ax[3, 2].hist(df['No-show'])\n",
    "ax[3, 2].set_title('No-show')\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation<a class=\"anchor\" id=\"preparation\"></a>\n",
    "Based on the findings and the discussion from the first two sections, we can now start the pre-processing. As first general steps we will change column names and convert binary attributes into an object type.\n",
    "\n",
    "Ask yourself at the beginning:\n",
    "* *Which working steps are to be taken on the basis of the previous findings?*\n",
    "* *What must be considered?*\n",
    "* *What additional information could be relevant?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop IDs, rename columns in order to correct spelling and get 'cleaned' names\n",
    "df = df.drop(['PatientId', 'AppointmentID'], axis = 1).rename(columns = {'Hipertension': 'Hypertension',\n",
    "                                                                         'Handcap': 'Handicap',\n",
    "                                                                         'SMS_received': 'SMSReceived',\n",
    "                                                                         'No-show': 'NoShow'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary attributes to object type columns\n",
    "df['Scholarship'] = df['Scholarship'].astype('object')\n",
    "df['Hypertension'] = df['Hypertension'].astype('object')\n",
    "df['Diabetes'] = df['Diabetes'].astype('object')\n",
    "df['Alcoholism'] = df['Alcoholism'].astype('object')\n",
    "df['Handicap'] = df['Handicap'].astype('object')\n",
    "df['SMSReceived'] = df['SMSReceived'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Age'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct age of -1\n",
    "df.loc[df['Age'] < 0, 'Age'] = 0                    # Other possibility is to drop this row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with weekday names\n",
    "df['WeekdayScheduled'] = df['ScheduledDay'].dt.weekday_name\n",
    "df['WeekdayAppointment'] = df['AppointmentDay'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference in days between scheduling and appointment\n",
    "df['Waiting'] = (df['AppointmentDay'].dt.date - df['ScheduledDay'].dt.date) / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hour when appointment was scheduled\n",
    "df['ArrangementHour'] = df['ScheduledDay'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original date columns\n",
    "df.drop(['ScheduledDay', 'AppointmentDay'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas for columns with non-binary values\n",
    "df = pd.get_dummies(df, columns = ['Neighbourhood', 'WeekdayScheduled', 'WeekdayAppointment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn for binary columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for c in ['Gender', 'NoShow']:\n",
    "    l = LabelEncoder()\n",
    "    df[c] = l.fit_transform(df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and evaluation<a class=\"anchor\" id=\"modeling\"></a>\n",
    "Now, after the data has been prepared for modelling, we can proceed with the application of different machine learning algorithms. For this purpose we will include a number of additional packages/modules. Think about this:\n",
    "\n",
    "* *What can be done to obtain a well generalising model?*\n",
    "* *How can I measure performance?*\n",
    "* *What do I have to compare the performance with or is a metric absolute?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and label into two NumPy-arrays\n",
    "X = df.drop(['NoShow'], axis = 1)\n",
    "y = df['NoShow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.35,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier object and start training\n",
    "clf_dt = DecisionTreeClassifier(max_depth = 4)  # restrict the tree fixed to four levels to get better display \n",
    "clf_dt = clf_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the indication about the most important features\n",
    "print(\"Feature Importance:\\n\")\n",
    "for name, importance in zip(X.columns, np.sort(clf_dt.feature_importances_)[::-1]):\n",
    "    print(\"{}: {:.2f}\".format(name, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix and accuracy\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate null accuracy\n",
    "1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Source(export_graphviz(clf_dt,\n",
    "                               out_file = None,\n",
    "                               feature_names = X.columns,\n",
    "                               class_names = ['No', 'Yes'],\n",
    "                               filled = True))\n",
    "display(SVG(graph.pipe(format = 'svg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier object and start training\n",
    "clf_rf = RandomForestClassifier(random_state = 42)\n",
    "clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the indication about the most important features\n",
    "print(\"Feature Importance:\\n\")\n",
    "for name, importance in zip(X.columns, np.sort(clf_rf.feature_importances_)[::-1]):\n",
    "    print(\"{}: {:.2f}\".format(name, importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix and accuracy\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [10, 20, 30],\n",
    "          'max_depth':[3, 4, 5]}\n",
    "clf_rf2 = RandomForestClassifier(random_state = 42)\n",
    "clf_grid = GridSearchCV(clf_rf2, params, cv = 5, n_jobs = -1, verbose = 1)\n",
    "clf_grid.fit(X_train, y_train)\n",
    "print(clf_grid.best_params_)\n",
    "print(clf_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "Please download the data set about campus recruitment [[3]](#roshan2020). Follow the CRISP-DM steps through to modeling. Use a Support Vector Machine combined with a Grid Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References<a class=\"anchor\" id=\"references\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]<a class=\"anchor\" id=\"sklearn2020\"></a> The scikit-learn developers (2020). scikit-learn. Retrieved 2020-04-02 from https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2]<a class=\"anchor\" id=\"jonihoppen2017\"></a> JoniHoppen (2017). Medical Appointment No Shows, Why do 30% of patients miss their scheduled appointments?, Version 5. Retrieved 2020-05-04 from https://www.kaggle.com/joniarroba/noshowappointments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3]<a class=\"anchor\" id=\"roshan2020\"></a> Ben Roshan D (2020). Campus Recruitment, Academic and Employability Factors influencing placement, Version 1. Retrieved 2020-05-04 from https://www.kaggle.com/benroshan/factors-affecting-campus-placement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
